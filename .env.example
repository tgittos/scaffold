# OpenAI Configuration
OPENAI_API_KEY="sk-proj-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
# API_URL=https://api.openai.com/v1/chat/completions
# MODEL=gpt-4o-mini
# CONTEXT_WINDOW=128000

# Anthropic Configuration
ANTHROPIC_API_KEY="sk-ant-api03-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
# API_URL=https://api.anthropic.com/v1/messages
# MODEL=claude-3-5-sonnet-20241022
# CONTEXT_WINDOW=200000

# Local Model Configuration (e.g., LM Studio)
# API_URL=http://localhost:1234/v1/chat/completions  
# MODEL=qwen/qwen-2.5-coder-32b
# CONTEXT_WINDOW=32768

# Optional: Override max response tokens (defaults to auto-calculated based on context window)
# MAX_TOKENS=4096
