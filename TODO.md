- Examine how conversation compaction and context size management currently works, and if and how it integrations into the document store. Determine if compaction is even required any more in context of the memory functionality, and refactor.
- The tool handling in the tools system is a giant if-then-else statement. This is unmaintainable. Re-architect and refactor the tool handling to be clear and maintainable.
- The file tools don't reveal much to the user about what files the agent is reading and what directories it's looking in.
- The config system still doesn't pull API keys out of the environment properly. When the config file is autogenerated on first boot, it MUST read both OPENAI_API_KEY and ANTHROPIC_API_KEY and ensure they are written to the config file as openai_api_key and anthropic_api_key respectively. If the environment values are missing, the keys MUST appear in the generated config file with blank values.
- Investigate the feasibility of moving all AI driven memory storage (conversation tracking, remembering things the user asks, etc) into a background process. This would mean that memory operations aren't logged to the user, but that's ok. If it seems possible, compose a plan for this refactor and execute it.
- Implement a new tool called the `TaskTool`. This tool should essentially invoke Ralph in one-shot mode in a sub-process, and return the result to the main agent. This tool is intended to expand Ralphs context window by allowing Ralph to dispatch task descriptions similar to the ones in this TODO, and retrieve the results once the task is done.
- Examine the codebase and understand the full feature set and capability of this tool. Update the README.md, ARCHITECTURE.md, and CODE_OVERVIEW.md files to reflect the current state. When updating the README.md, keep the tone and update the examples in context of the new functionality.
- Write Github actions to use the devcontainer in this project to build ralph. Build ralph on PRs and merges, and release it on tags. Use Githubs releases feature.
