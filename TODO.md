- Source .env, verifying you have an OPENAI_API_KEY. Then build and start ralph. Observe the default config file created. Fix ralph to automatically read the OpenAI API key from the environment and insert it into the generated config file. Also, ensure the config variable for the API key is in the generated file, but blank, if there is no OpenAI API key on the environment
- Check the implementation of the MAX_TOKENS and MAX_CONTEXT_WINDOW configurations. Something seems off and wrong. Remove them if possible. They were there for local LLM overrides due to various different model context window supports. It still may be needed, but refactored.
- The user needs the ability to maintain the vector DB to manage ralph's memories and remove bad chunks and fix metadata. Implement a user facing CLI tool submodule that can be accessed in the CLI through a slash command (eg: `/memory delete chunk-123`).
- Refactor the conversation tracking system to just save every message sent to and received by the AI is stored in the vector db, not in a file. Ensure the agent queries the vector DB for recent history, in a sliding window. The agent should also be able to get more conversation history via tools if it needs. Implement missing vector DB functionality if you find you are unable to search by time frames in the vector DB.
- Write Github actions to use the devcontainer in this project to build ralph. Build ralph on PRs and merges, and release it on tags. Use Githubs releases feature.
