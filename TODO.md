- Integrate the in-memory vector DB and tool to support RAG. I want the llm to manage the "memories" stored in it. The user should be able to instruct the LLM to remember something, and the LLM should automatically query the vector db for relevant context when appropriate. The LLM should also decide to store any textual fetched content from the internet and important memories and notes it determines based on user feedback, ie - remembering when the user corrects the LLMs behavior
- The CLI interface for this application supports a subset of Readline-like features. Research how to compile Readline with Cosmopolitan, and refactor the user input functionality to use Readline.
- Write a model-context-protocol client module. Integrate it into the ralph client. Ensure the end user can configure MCP servers with a `ralph.config.json` file at either `~/.local/ralph` or `./ralph.config.json` similar to how Claude Code's MCP configuration works.
- Write Github actions to use the devcontainer in this project to build ralph. Build ralph on PRs and merges, and release it on tags. Use Githubs releases feature.
